apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-config
  namespace: {{ .Values.namespace }}
  labels:
    app: flink
data:
  base-config: |+
    kafka {
      broker-servers = "{{ .Values.kafka_host }}:9092"
      producer.broker-servers = "{{ .Values.kafka_host }}:9092"
      consumer.broker-servers = "{{ .Values.kafka_host }}:9092"
      zookeeper = "{{ .Values.zookeeper_host }}:2181"
      producer {
        max-request-size = 1572864
        batch.size = 98304
        linger.ms = 10
        compression = "snappy"
      }
      output.system.event.topic = "dev.system.events"
    }
    job {
      env = "dev"
      enable.distributed.checkpointing = false
      statebackend {
        blob {
          storage {
            account = "{{ .Values.cloud_storage_key }}.blob.core.windows.net"
            container = "{{ .Values.cloud_storage_flink_bucketname }}"
            checkpointing.dir = "checkpoint"
          }
        }
        base.url = "wasbs://"${job.statebackend.blob.storage.container}"@"${job.statebackend.blob.storage.account}"/"${job.statebackend.blob.storage.checkpointing.dir} }
    }
    task {
      parallelism = 1
      consumer.parallelism = 1
      checkpointing.compressed = true
      checkpointing.interval = 10
      checkpointing.pause.between.seconds = 3000
      restart-strategy.attempts = 3
      restart-strategy.delay = 30000 # in milli-seconds
    }
  
  
    redis {
    host = {{ .Values.redis_host }}
    port = 6379
    connection {
      max = 2
      idle.min = 1
      idle.max = 2
      minEvictableIdleTimeSeconds = 120
      timeBetweenEvictionRunsSeconds = 300
        }
    }
    lms-cassandra {
    host = {{ .Values.cassandra_host }}
    port = "9042"
    }
  
    neo4j {
    routePath = "bolt://{{ .Values.neo4j_host }}:7687"
    graph = "domain"
    }
  
    es {
      basePath = "{{ .Values.elasticsearch_host }}:9200"
    }
  
  {{ if eq .Release.Name "search-indexer" }}
  search-indexer: |+
        include file("/data/flink/conf/base-config.conf")
        job {
          env = "dev"
        }
        kafka {
          event.max.size = "1048576" # Max is only 1MB
          input.topic = "dock.learning.graph.events"
          error.topic = "dpck.learning.events.failed"
          groupId = "dock-search-indexer-group"
          producer {
            max-request-size = 5242880
          }
        }
        task {
           consumer.parallelism = 1
           router.parallelism = 1
           compositeSearch.parallelism = 1
           dialcodeIndexer.parallelism = 1
           dialcodemetricsIndexer.parallelism = 1
        }
        compositesearch.index.name = "compositesearch"
        dialcode.index.name = "dialcode"
        dailcodemetrics.index.name = "dialcodemetrics"
        restrict.metadata.objectTypes = []
        nested.fields = ["badgeAssertions", "targets", "badgeAssociations", "plugins", "me_totalTimeSpent", "me_totalPlaySessionCount", "me_totalTimeSpentInSec", "batches", "trackable", "credentials", "discussionForum", "provider", "osMetadata", "actions", "transcripts", "accessibility"]
        schema.definition_cache.expiry = 14400
        restrict {
          metadata.objectTypes = []
          objectTypes = ["EventSet", "EventSetImage", "Event", "EventImage", "Questionnaire", "Misconception", "FrameworkType", "Concept", "Misconception", "Language", "Reference", "Dimension", "Method", "Library", "Domain", "Api"]
        }
        ignored.fields=["responseDeclaration", "body", "options", "lastStatusChangedOn", "SYS_INTERNAL_LAST_UPDATED_ON", "sYS_INTERNAL_LAST_UPDATED_ON", "branchingLogic"]

        cloud_storage_type="{{ .Values.cloud_service_provider }}"
        cloud_storage_key="{{ .Values.cloud_storage_key }}"
        cloud_storage_secret="{{ .Values.cloud_storage_secret }}"
        cloud_storage_container="{{ .Values.cloud_storage_content_bucketname }}"

        cloudstorage.metadata.replace_absolute_path=false
        cloudstorage.relative_path_prefix=CONTENT_STORAGE_BASE_PATH
        cloudstorage.read_base_path="https://{{ .Values.cloud_storage_key }}.core.windows.net"
        cloudstorage.write_base_path=["https://{{ .Values.cloud_storage_key }}.core.windows.net","https://obj.dev.sunbird.org"]
        cloudstorage.metadata.list=["appIcon", "artifactUrl", "posterImage", "previewUrl", "thumbnail", "assetsMap", "certTemplate", "itemSetPreviewUrl", "grayScaleAppIcon", "sourceURL", "variants", "downloadUrl", "streamingUrl", "toc_url", "data", "question", "solutions", "editorState", "media", "pdfUrl", "transcripts"]


  flink-conf: |+
      jobmanager.memory.flink.size: 1024m
      taskmanager.memory.flink.size: 1024m
      taskmanager.numberOfTaskSlots: 1
      jobManager.numberOfTaskSlots: 1
      parallelism.default: 1
      jobmanager.execution.failover-strategy: region
      taskmanager.memory.network.fraction: 0.1
      scheduler-mode: reactive
      heartbeat.timeout: 8000
      heartbeat.interval: 5000
      taskmanager.memory.process.size: 1700m
      jobmanager.memory.process.size: 1600m
      # classloader.resolve-order: "parent-first"
      # state.savepoints.dir: file:///tmp
 
  {{- end }}

  {{ if eq .Release.Name "asset-enrichment" }}
  asset-enrichment: |+
    include file("/data/flink/conf/base-config.conf")
    job {
      env = "dev"
    }

    kafka {
      input.topic = "dock.learning.job.request"
      groupId = "dock-asset-enrichment-group"
      video_stream.topic = "dock.content.postpublish.request"
    }

    task {
      consumer.parallelism = 1
      router.parallelism = 1
      videoEnrichment.parallelism = 1
      imageEnrichment.parallelism = 1
    }

    content {
      stream {
        enabled = true
        mimeType = ["video/mp4", "video/webm"]
      }
      youtube {
        applicationName = "fetch-youtube-license"
        regexPattern = ["\\?vi?=([^&]*)", "watch\\?.*v=([^&]*)", "(?:embed|vi?)/([^/?]*)", "^([A-Za-z0-9\\-\\_]*)"]
      }
      upload.context.driven = true
      max.iteration.count = 2
    }

    thumbnail.max {
      sample = 5
      size.pixel = 150
    }
  
    content_youtube_apikey=""
    cloud_storage_type="{{ .Values.cloud_service_provider }}"
    cloud_storage_key="{{ .Values.cloud_storage_key }}"
    cloud_storage_secret="{{ .Values.cloud_storage_secret }}"
    cloud_storage_container="{{ .Values.cloud_storage_content_bucketname }}"

    cloudstorage.metadata.replace_absolute_path=false
    cloudstorage.relative_path_prefix="CONTENT_STORAGE_BASE_PATH"
    cloudstorage.read_base_path="https://{{ .Values.cloud_storage_key }}.core.windows.net"
    cloudstorage.write_base_path=["https://{{ .Values.cloud_storage_key }}.core.windows.net"]
    cloudstorage.metadata.list=["appIcon", "artifactUrl", "posterImage", "previewUrl", "thumbnail", "assetsMap", "certTemplate", "itemSetPreviewUrl", "grayScaleAppIcon", "sourceURL", "variants", "downloadUrl", "streamingUrl", "toc_url", "data", "question", "solutions", "editorState", "media", "pdfUrl", "transcripts"]

  flink-conf: |+
    jobmanager.memory.flink.size: 1024m
    taskmanager.memory.flink.size: 1024m
    taskmanager.numberOfTaskSlots: 1
    jobManager.numberOfTaskSlots: 1
    parallelism.default: 1
    jobmanager.execution.failover-strategy: region
    taskmanager.memory.network.fraction: 0.1
    scheduler-mode: reactive
    heartbeat.timeout: 8000
    heartbeat.interval: 5000
    taskmanager.memory.process.size: 1700m
    jobmanager.memory.process.size: 1600m
    # classloader.resolve-order: "parent-first"
    # state.savepoints.dir: file:///tmp

  {{- end }}  
  log4j_console_properties: |+
{{ .Values.log4j_console_properties | indent 4 }}
