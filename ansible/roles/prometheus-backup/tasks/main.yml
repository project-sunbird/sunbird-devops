- name: ensure prometheus is stopped before backup
  shell: "docker service scale monitor_prometheus=0 && sleep 10"
  delegate_to: "{{groups['swarm-bootstrap-manager'][0]}}"

- name: Starting Prometheus backup 
  block:
    - name: ensure backup dir exists
      file: path="{{ prometheus_backup_dir }}" state=directory

    - name: ensure backup dir is empty
      shell: "rm -rf {{ prometheus_backup_dir }}/*"

    - set_fact:
        prometheus_backup_gzip_file_name: "prometheus_backup_{{ lookup('pipe', 'date +%Z-%Y-%m-%d-%H-%M-%S') }}.tar.gz"

    - set_fact:
        prometheus_backup_gzip_file_path: "{{ prometheus_backup_dir }}/{{ prometheus_backup_gzip_file_name }}"

    - name: Save backup
      archive:
        path: "{{prometheus_data_dir}}"
        dest: "{{prometheus_backup_gzip_file_path}}"
  always:
    - name: ensure prometheus is started after backup
      shell: "docker service scale monitor_prometheus=1"
      delegate_to: "{{groups['swarm-bootstrap-manager'][0]}}"

- name: upload file to azure storage
  include_role:
    name: azure-cloud-storage
    tasks_from: blob-upload.yml
  vars:
    blob_container_name: "{{ prometheus_backup_storage }}"
    container_public_access: "off"
    blob_file_name: "{{ prometheus_backup_gzip_file_name }}"
    local_file_or_folder_path: "{{ prometheus_backup_gzip_file_path }}"
    storage_account_name: "{{ azure_management_storage_account_name }}"
    storage_account_key: "{{ azure_management_storage_account_key }}"
  when: cloud_service_provider == "azure"

- name: upload file to aws s3
  include_role:
    name: aws-cloud-storage
    tasks_from: upload.yml
  vars:
    s3_bucket_name: "{{ aws_management_s3_bucket_name }}"
    aws_access_key_id: "{{ aws_management_bucket_access_key }}"
    aws_secret_access_key: "{{ aws_management_bucket_secret_access_key }}"
    aws_default_region: "{{ aws_region }}"
    local_file_or_folder_path: "{{ prometheus_backup_gzip_file_path }}"
    s3_path: "{{ prometheus_backup_storage }}/{{ prometheus_backup_gzip_file_name }}"
  when: cloud_service_provider == "aws" 
  
- name: upload file to gcloud storage
  include_role:
    name: gcp-cloud-storage
    tasks_from: upload.yml
  vars:
    gcp_bucket_name: "{{ gcloud_management_bucket_name }}"
    dest_folder_name: "{{ prometheus_backup_storage }}"
    dest_file_name: "{{ prometheus_backup_gzip_file_name }}"
    local_file_or_folder_path: "{{ prometheus_backup_gzip_file_path }}"
  when: cloud_service_provider == "gcloud"

- name: clean up backup dir after upload
  file: path="{{ prometheus_backup_dir }}" state=absent
