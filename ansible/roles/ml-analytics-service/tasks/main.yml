---
# tasks file for data-pipeline
- name: Git checkout
  git:
    repo: 'https://github.com/Sunbird-Ed/ml-analytics-service.git'
    dest: "{{ BASEPATH }}/ml-analytics-service"
    version: "{{ ml_analytics_version }}"
    depth: "1"
    force: yes

- name: CREATE THE USER
  user:
    name: "{{ USER }}"
    state: present
    home: "/home/{{ USER }}"
    shell: /bin/bash

- name: INSTALL THE PACKGES
  apt:
    update_cache: yes
    name:
      - openjdk-8-jdk
      - software-properties-common
      - python3-pip
      - python3-venv
      - python3-virtualenv
      - zip
      - unzip
    state: present

- name: CHANGE THE OWNERSHIP FOR THIS {{ BASEPATH }} DIRECTORY
  file:
    path: "{{ item }}"
    mode: "0755"
    recurse: yes
    state: directory
    owner: "{{ USER }}"
    group: "{{ USER }}"
  loop:
    - "{{ BASEPATH }}"
    - "{{ WORKDIR }}"
    - "{{ WORKDIR }}/faust_as_service"
    
- name: Delete the virtualenv DIR
  shell: "rm -rf {{ WORKDIR }}/spark_env"
  become: true
  
- name: Install python virtual environment
  shell: "cd {{ WORKDIR }} && virtualenv --python=python3.8 spark_venv"
  become: true
  
- name: Change the ownership of virtual env
  become: yes
  file:
    path: "{{ WORKDIR }}/spark_env"
    state: directory
    owner: "{{ USER }}"
    group: "{{ USER }}"
    mode: "0755"

- name: Create necessary logs folders for pipeline
  become: yes
  file:
    path: "{{ item }}"
    state: directory
    owner: "{{ USER }}"
    group: "{{ USER }}"
    mode: "0755"
  loop:
    - "{{ WORKDIR }}/logs/observation/status"
    - "{{ WORKDIR }}/logs/observation/evidence"
    - "{{ WORKDIR }}/logs/project"
    - "{{ WORKDIR }}/logs/survey"
    - "{{ WORKDIR }}/logs/survey/evidence"

- name: Install packages from requirement.txt
  pip:
    virtualenv: "{{WORKDIR }}/spark_venv"
    virtualenv_python: python3.8
    requirements: "{{ WORKDIR }}/ml-analytics-service/requirements.txt"
    extra_args: --upgrade

- name: Creating a faust service shell file in executable mode
  copy:
    src: files/faust.sh
    dest: "{{ WORKDIR }}/faust_as_service/faust.sh"
    owner: "{{ USER }}"
    group: "{{ USER }}"
    backup: yes
    mode: 0777

- name: CREATION THE SYSTEMD faust_observation FILE
  copy:
    src: files/{{ item }}
    dest: "{{ SYSTEMDDIR }}"
  with_items:
    - faust_observation.service
    - faust_observation_evidence.service
    - faust_survey.service
    - faust_survey_evidence.service

- name: Templating the config.j2 to config.ini
  template:
    src: "config.j2"
    dest: "{{ config_path }}/config.ini"
    backup: yes

- name: Templating the shell_script_config.j2 to shell_script_config
  template:
    src: "shell_script_config.j2"
    dest: "{{ config_path }}/shell_script_config"
    backup: yes
    
- name: SYSTEMD DAEMON-RELOAD
  systemd:
    daemon_reload: yes

- name: START AND ENABLE THE SERVICE
  systemd:
    name: "{{ item }}"
    enabled: yes
    state: restarted
  loop:
    - faust_observation.service
    - faust_observation_evidence.service
    - faust_survey.service
    - faust_survey_evidence.service

- name: CREATE THE CRON BATCH INGESTION
  cron:
    name: "Run Batch Ingestion Job"
    user: "{{ USER }}"
    minute: "30"
    hour: "18"
    job: "{{ BASEPATH }}/ml-analytics-service/run.sh > {{ BASEPATH }}/ml-analytics-service/crontab_job.log"

- name: CREATE THE CRON NVSK Data Upload
  cron:
    name: "NVSK Data Upload JOB"
    user: "{{ USER }}"
    minute: "30"
    hour: "7"
    weekday: "4"
    job: "{{ BASEPATH }}/run_weekly.sh > {{ BASEPATH }}/ml-analytics-service/nvsk_data_weekly.logs"
