<configuration>

	<conversionRule conversionWord="coloredLevel" converterClass="play.api.libs.logback.ColoredLevel" />

	<!-- transaction-event-trigger START -->
	<timestamp key="timestamp" datePattern="yyyy-MM-dd"/>
	<!-- common transactions logs -->
	<appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
		<encoder>
			<pattern>%d %msg%n</pattern>
		</encoder>
	</appender>

	<appender name="ASYNCSTDOUT" class="ch.qos.logback.classic.AsyncAppender">
		<appender-ref ref="STDOUT" />
	</appender>


	<logger name="play" level="INFO" />
	<logger name="DefaultPlatformLogger" level="INFO" />
	<!-- Telemetry Loggers-->

	<root level="INFO">
		<appender-ref ref="ASYNCSTDOUT" />
	</root>


	<appender name="kafka-appender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
		<encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
			<pattern>%msg</pattern>
		</encoder>

		<topic>{{env_name}}.telemetry.raw</topic>
		<!-- ensure that every message sent by the executing host is partitioned to the same partition strategy -->
        <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.HostNameKeyingStrategy" />
        <!-- block the logging application thread if the kafka appender cannot keep up with sending the log messages -->
        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.BlockingDeliveryStrategy">
            <!-- wait indefinitely until the kafka producer was able to send the message -->
            <timeout>0</timeout>
        </deliveryStrategy>

		<!-- each <producerConfig> translates to regular kafka-client config (format: key=value) -->
		<!-- producer configs are documented here: https://kafka.apache.org/documentation.html#newproducerconfigs -->
		<!-- bootstrap.servers is the only mandatory producerConfig -->
		<producerConfig>bootstrap.servers={{lp_kafka_url}}</producerConfig>
		<!-- restrict the size of the buffered batches to 8MB (default is 32MB) -->
        <producerConfig>buffer.memory=8388608</producerConfig>

        <!-- If the kafka broker is not online when we try to log, just block until it becomes available -->
        <producerConfig>metadata.fetch.timeout.ms=99999999999</producerConfig>
        <!-- define a client-id that you use to identify yourself against the kafka broker -->
        <producerConfig>client.id=${HOSTNAME}-${CONTEXT_NAME}-logback-restrictive</producerConfig>
        <!-- Log every log message that could not be sent to kafka to STDERR -->
        <appender-ref ref="ASYNCSTDOUT"/>

	</appender>

	<logger name="TelemetryEventLogger" level="INFO">
		<appender-ref ref="kafka-appender" />
	</logger>

</configuration>
