# Default values for statsd-exporter.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: quay.io/prometheus/statsd-exporter
  pullPolicy: IfNotPresent
  imageTag: v0.17.0

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

namespace: monitoring

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name:

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

ports:
  - containerPort: 9102
    name: http
  - containerPort: 9125
    name: statsd-tcp
  - containerPort: 9125
    protocol: UDP
    name: statsd-udp

service:
  type: ClusterIP
  ports:
  - port: 9102
    name: http
    targetPort: 9102
  - port: 9125
    name: statsd-tcp
    targetPort: 9125
  - port: 9125
    name: statsd-udp
    targetPort: 9125
    protocol: UDP

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths: []
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
#  requests:
#    cpu: 50m
#    memory: 128Mi
#  limits:
#    cpu: 100m
#    memory: 256Mi

nodeSelector: {}

tolerations: []

affinity: {}

# Configmap for statsd
configMapValues:
    defaults:
      timer_type: histogram
      histogram_options:
        buckets: [.005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10]
      match_type: glob
      glob_disable_ordering: false
    mappings:
      - labels:
          api: $1
        match: kong.*.request.count
        name: kong_request_count
      - labels:
          api: $1
          status_code: $2
        match: kong.*.request.status.*
        name: kong_request_status_count
      - labels:
          api: $1
        match: kong.*.latency
        name: kong_latency_time
      - labels:
          api: $1
        match: kong.*.upstream_latency
        name: kong_upstream_latency_time
      - labels:
          api: $1
        match: kong.*.request.size
        histogram_options:
          buckets: [ 1, 5, 10, 25, 50, 100, 1000, 10000, 25000, 50000 ]
        name: kong_request_size
      - labels:
          api: $1
        match: kong.*.response.size
        histogram_options:
          buckets: [ 1, 5, 10, 25, 50, 100, 250, 500, 1000, 2000 ]
        name: kong_response_size
      - labels:
          api: $1
        match: kong.*.user.uniques
        name: kong_unique_users_v2  
      - labels:
          api: $1
          username: $2
        match: kong.*.user.*.count
        name: kong_request_per_user
      - labels:
          api: $1
          username: $2
        match: kong.*.user.*.request.count
        name: kong_request_per_user_v2  
      - labels:
          api: $1
          username: $2
          status: $3
        match: kong.*.user.*.status.*
        name: kong_status_count_per_user  
      - labels:
          api: $1
          username: $2
          status: $3
        match: kong.*.user.*.request.status.*
        name: kong_status_count_per_user_v2
      - labels:
          api: $1
          username: $2
        match: kong.*.user.*.status.total
        name: kong_status_count_per_user_total
      - labels:
          api: $1
          username: $2
        match: kong.*.user.*.request.status.total
        name: kong_status_count_per_user_total_v2  
      - match: "."
        match_type: regex
        action: drop
        name: "dropped"

# This section will create service monitor for prometheus operator
serviceMonitor:
  enabled: true
  labels: # labels with which the prometheus choose the serviceMonitor
    app: monitoring
    release: prometheus-operator
