apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      volumes:
        - name: proxy-config
          configMap:
            name: proxy-default
        - name: nginx-config
          configMap:
            name: nginx-config
      containers:
      - name: name
        image: sunbird/proxy:release-2.4.0
        volumeMounts:
          - name: proxy-config
            mountPath: /etc/nginx/conf.d/default.conf
            subPath: proxy-default.conf
            readOnly: true
          - name: nginx-config
            mountPath: /etc/nginx/nginx.conf
            subPath: nginx.conf
            readOnly: true
        resources:
          requests:
            cpu: 100m
            memory: 200Mi
        ports:
        - containerPort: 80
          name: http
        - containerPort: 443
          name: https
        - containerPort: 9145
          name: http-metrics
---
apiVersion: v1
kind: Service
metadata:
  name: nginx
spec:
  type: LoadBalancer
  ports:
  - port: 80
    name: http
    targetPort: 80
  - port: 9145
    name: http-metrics
    targetPort: 9145
  selector:
    app: nginx

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: proxy-default
data:
  proxy-default.conf: |
    server {
      listen 80;
      resolver 10.43.0.10 valid=30s;
      location / {
        proxy_pass http://headerecho:4000;
      }
    }
  
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
data: 
  nginx.conf: |
    user  nginx;
    worker_processes  1;
    
    error_log  /var/log/nginx/error.log warn;
    pid        /var/run/nginx.pid;
    
    events {
        worker_connections  10000;
    }
  
    http {
        include       /etc/nginx/mime.types;
        default_type  application/octet-stream;
        resolver 10.43.0.10 valid=30s;
    
        lua_load_resty_core off;
        log_format  main  '$remote_addr - $remote_user [$time_local] '
                          '"$request" $status $body_bytes_sent '
                          '$request_time $upstream_response_time $pipe'
                          '"$http_referer" "$http_user_agent"';
    
        access_log  /var/log/nginx/access.log  main;
    
        # Shared dictionary to store metrics
        lua_shared_dict prometheus_metrics 10M;
        lua_package_path "/etc/nginx/lua_modules/?.lua";
        # Defining metrics
        init_by_lua '
          prometheus = require("prometheus").init("prometheus_metrics")
          metric_requests = prometheus:counter(
            "nginx_http_requests_total", "Number of HTTP requests", {"host", "status", "request_method"})
          metric_latency = prometheus:histogram(
            "nginx_http_request_duration_seconds", "HTTP request latency", {"host"})
          metric_connections = prometheus:gauge(
            "nginx_http_connections", "Number of HTTP connections", {"state"})
        ';
    
        # Collecting metrics
        log_by_lua '
          metric_requests:inc(1, {ngx.var.server_name, ngx.var.status, ngx.var.request_method})
          metric_latency:observe(tonumber(ngx.var.request_time), {ngx.var.server_name})
        ';
    
        header_filter_by_lua_block {
         ngx.header["server"] = nil
        }
    
        sendfile        on;
        #tcp_nopush     on;
        client_max_body_size 60M;
    
        keepalive_timeout  65s;
        keepalive_requests 200;
    
        # Nginx connection limit per ip
        limit_conn_zone $binary_remote_addr zone=limitbyaddr:10m;
        limit_conn_status 429;
    
        include /etc/nginx/conf.d/*.conf;
    
       server {
         listen 9145;
         location /metrics {
           content_by_lua '
             metric_connections:set(ngx.var.connections_reading, {"reading"})
             metric_connections:set(ngx.var.connections_waiting, {"waiting"})
             metric_connections:set(ngx.var.connections_writing, {"writing"})
             prometheus:collect()
           ';
         }
       }
    }
