# ------------------------------------------------------------------------------------------------------------ #
# Mandatorty variables - DO NOT LEAVE ANYTHING BLANK #
cloud_service_provider: ""       # Your cloud service provider name. Supported values are aws, azure, gcloud
domain_name: ""          # your domain name like example.com
# docker hub details
dockerhub: "change.docker.url"                                      # docker hub username or url incase of private registry
private_ingressgateway_ip: ""                        # your private kubernetes load balancer ip

# Cloud Service Provider Variables
cloud_public_storage_accountname: ""  # If cloud_service_provider is aws--> access key, gcp--> service account name, azure--> storage account name
cloud_public_storage_endpoint: ""     # Not required in current release
cloud_public_storage_region: ""       # If cloud_service_provider is aws or oci update this variable
cloud_public_storage_project: ""      # If cloud_service_provider is gcp update this variable
cloud_public_storage_namespace: ""    # If cloud_service_provider is oci update this variable

cloud_private_storage_accountname: "" # If cloud_service_provider is aws--> access key, gcp--> service account name, azure--> storage account name
cloud_private_storage_endpoint: ""    # Not required in current release
cloud_private_storage_region: ""      # If cloud_service_provider is aws or oci update this variable
cloud_private_storage_project: ""     # If cloud_service_provider is gcp update this variable
cloud_private_storage_namespace: ""    # If cloud_service_provider is oci update this variable

cloud_management_storage_accountname: ""  # If cloud_service_provider is aws--> access key, gcp--> service account name, azure--> storage account name
cloud_management_storage_endpoint: ""     # Not required in current release
cloud_management_storage_region: ""       # If cloud_service_provider is aws or oci update this variable
cloud_management_storage_project: ""      # If cloud_service_provider is gcp update this variable
cloud_management_storage_namespace: ""    # If cloud_service_provider is oci update this variable

cloud_artifact_storage_accountname: ""  # If cloud_service_provider is aws--> access key, gcp--> service account name, azure--> storage account name
cloud_artifact_storage_endpoint: ""     # Not required in current release
cloud_artifact_storage_region: ""       # If cloud_service_provider is aws or oci update this variable
cloud_artifact_storage_project: ""      # If cloud_service_provider is gcp update this variable
cloud_artifact_storage_namespace: ""    # If cloud_service_provider is oci update this variable

# Create object storage for each below mentioned variables and update accordingly
cloud_storage_certqr_bucketname: ""
cloud_storage_chatbot_bucketname: ""
cloud_storage_dial_bucketname: ""
cloud_storage_flink_bucketname: ""
cloud_storage_playercdn_bucketname: ""
cloud_storage_public_bucketname: ""
cloud_storage_publicreports_bucketname: ""
cloud_storage_privatereports_bucketname: ""
cloud_storage_samiksha_bucketname: ""
cloud_storage_schema_bucketname: ""
cloud_storage_sourcing_bucketname: ""
cloud_storage_offlineinstaller_bucketname: ""
cloud_storage_content_bucketname: ""
cloud_storage_telemetry_bucketname: ""
cloud_storage_termsandcondtions_bucketname: ""
cloud_storage_user_bucketname: ""
cloud_storage_desktopappcrashlogs_bucketname: ""
cloud_storage_label_bucketname: ""
cloud_storage_certservice_bucketname: ""
cloud_storage_uci_bucketname: "" 
cloud_storage_artifacts_bucketname: ""

cloud_storage_management_bucketname: ""  # This object storage is used for backups

## Enable below vars to upload database backups in seperate buckets 
# cloud_storage_cassandrabackup_bucketname: ""
# cloud_storage_dpcassandrabackup_bucketname: ""
# cloud_storage_dppostgresbackup_bucketname: ""
# cloud_storage_dpredisbackup_bucketname: ""
# cloud_storage_esbackup_bucketname: ""
# cloud_storage_influxdbbackup_bucketname: ""
# cloud_storage_jenkinsbackup_bucketname: ""
# cloud_storage_mongobackup_bucketname: ""
# cloud_storage_neo4jbackup_bucketname: ""
# cloud_storage_redisbackup_bucketname: ""


# Uncomment the variable based on your cloud provider (as a default we have kept Azure variable uncommented)
# GCP
# cloud_storage_url: https://storage.cloud.google.com
# AWS
# cloud_storage_url: "https://s3.{{ cloud_public_storage_region }}.amazonaws.com"
# OCI
# cloud_storage_url: https://{{ cloud_public_storage_namespace }}.compat.objectstorage.{{ cloud_public_storage_region }}.oraclecloud.com/{{ bucket_name }}
# Azure
cloud_storage_url: "https://{{ cloud_public_storage_accountname }}.blob.core.windows.net"

# ------------------------------------------------------------------------------------------------------------ #
# Optional variables - Can be left blank if you dont plan to use the intended features
env: dev                  # some name like dev, preprod etc
proto: https               # http or https, preferably https

# Azure media streaming service
stream_base_url: "" # Media service streaming url
media_service_azure_tenant: "" # value have to be defined
media_service_azure_subscription_id: ""
media_service_azure_account_name: ""
media_service_azure_resource_group_name: ""
media_service_azure_token_client_key: ""
media_service_azure_token_client_secret: ""

# data exhaust alerts
data_exhaust_webhook_url: "slack.com"     # Slack webhook url
data_exhaust_Channel: "slack.com"         # Slack channel for data products alerts
secor_alerts_slack_channel: "slack.com"   # Slack channel name for secor alerts - Example #all_alerts_channel

# ------------------------------------------------------------------------------------------------------------ #
# Sensible defaults which you need not change - But if you would like to change, you are free to do so
data_exhaust_name: "datapipeline-monitoring"  # Slack notification name
postgres:
  db_url: "{{ groups['postgres'][0] }}"
  db_username: analytics
  db_name: analytics
  db_password: "{{dp_vault_pgdb_password}}"
  db_table_name: "{{env}}_consumer_channel_mapping"
  db_port: 5432
  db_admin_user: postgres
  db_admin_password: "{{dp_vault_pgdb_admin_password}}"

druid_postgres_user: druid # Do not change this
imagepullsecrets: "{{env}}registrysecret"                  # kubernetes imagePullSecrets
kubeconfig_path: /var/lib/jenkins/secrets/k8s.yaml         # kubeconfig file path on jenkins
core_kubeconfig_path: "{{ kubeconfig_path }}"              # kubeconfig file path on jenkins for core kube cluster, change this if you use separate kube cluster for core and KP + DP

# The below sets the kafka topics retention time to 1 day, if you use the defaults from the public repo, it will be 7 days
# If you want to retain the topics for 7 days, remove the below sections completely
# Ensure you have atleast 1 TB of disk to retain data for 7 days
ingestion_kafka_topics:
  - name: telemetry.ingestion
    num_of_partitions: 2
    replication_factor: 1
  - name: events.deviceprofile
    num_of_partitions: 2
    replication_factor: 1
  - name: telemetry.ingest
    num_of_partitions: 2
    replication_factor: 1

ingestion_kafka_overriden_topics:
  - name: telemetry.ingestion
    retention_time: 86400000
    replication_factor: 1
    max_message_bytes: 5242880
  - name: events.deviceprofile
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.ingest
    retention_time: 86400000
    replication_factor: 1
    max_message_bytes: 5242880

processing_kafka_overriden_topics:
  - name: analytics.job_queue
    retention_time: 86400000
    replication_factor: 1
  - name: analytics_metrics
    retention_time: 86400000
    replication_factor: 1
  - name: druid.events.error
    retention_time: 86400000
    replication_factor: 1
  - name: druid.events.log
    retention_time: 86400000
    replication_factor: 1
  - name: druid.events.summary
    retention_time: 86400000
    replication_factor: 1
  - name: druid.events.telemetry
    retention_time: 86400000
    replication_factor: 1
  - name: events.deviceprofile
    retention_time: 86400000
    replication_factor: 1
  - name: prom.monitoring.metrics
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.assess
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.assess.failed
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.assess.raw
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.audit
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.denorm
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.derived
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.derived.unique
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.duplicate
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.error
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.extractor.duplicate
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.extractor.failed
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.failed
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.ingest
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.metrics
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.raw
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.unique
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.unique.latest
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.unique.primary
    retention_time: 86400000
    replication_factor: 1
  - name: telemetry.unique.secondary
    retention_time: 86400000
    replication_factor: 1
  - name: ml.observation.raw
    retention_time: 86400000
    replication_factor: 1
  - name: ml.observation.druid
    retention_time: 86400000
    replication_factor: 1

