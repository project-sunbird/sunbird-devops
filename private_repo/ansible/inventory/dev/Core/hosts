# Alert manager nodes which should be clustered
# This values should be one of any manager node, if you've multinode cluster
[alert-manager:children]
# By default this value can be swarm-manager-1 or 2 or n; but for a single
# cluster it should be one value.
# If you have multiple cluster you can list all ips below one by one
swarm-manager-1

[swarm-manager-1]
18.0.0.15 swarm_master=true

# This host will make sure prometheus for all stateful services
# will run on a single node, as it has storage dependancy
# By default this host is same as docker swarm prometheus
[swarm-agent-for-prometheus-stateful:children]
swarm-agent-for-prometheus

[swarm-manager:children]
swarm-manager-1

[swarm-node-1]
11.3.0.27

[swarm-worker:children]
swarm-node-1

[keycloak-1]
18.3.1.6

[keycloak:children]
keycloak-1

[log-es-2]
18.3.1.6 es_instance_name=log-es-2 node_name=log-es-2 es_etc_node_master=true es_etc_node_data=true

[log-es:children]
log-es-2

[mongo_master]
11.2.3.75 mongodb_master=True

[mongo_replicas] #add ip in case replicaSet

[mongo:children]
mongo_master
mongo_replicas

[swarm-agent-for-prometheus-1]
18.0.0.15

[swarm-agent-for-prometheus:children]
swarm-agent-for-prometheus-1

[swarm-agent-for-prometheus-stateful:children]
swarm-agent-for-prometheus

[swarm-dashboard-1]
18.0.0.15

[swarm-dashboard:children]
swarm-dashboard-1

[swarm-agent-dashboard-1]
18.0.0.15

[swarm-agent-dashboard:children]
swarm-agent-dashboard-1

[alertmanager_stateful:children]
swarm-agent-dashboard

[swarm-agent-for-alertmanager-1]
18.0.0.15

[es-1]
18.3.0.4 es_instance_name=es-1 es_etc_node_master=true es_etc_node_data=true

[es-backup:children]
es-1

[log-es-backup:children]
log-es-2

[es:children]
es-1

[cassandra-1]
18.3.0.4

[cassandra:children]
cassandra-1

[postgresql-master-1]
18.3.0.4

[postgresql-master:children]
postgresql-master-1

[postgresql-slave-1]
18.3.0.4

[swarm-manager]
0.0.0.0    #### keep as it is

[postgresql-slave:children]
postgresql-slave-1

[postgres:children]
postgresql-slave
postgresql-master

[kafka-1]
18.3.1.5 kafka_id=1

[processing-cluster-kafka]
18.3.1.5

[kafka:children]
kafka-1

[processing-cluster-zookeepers]
18.3.1.5            # Zookeeper IP of processing cluster in Data pipeline

[ingestion-cluster-kafka]
18.3.0.5

[zookeeper:children]
processing-cluster-zookeepers

[lp-redis]
18.3.1.5            # Redis master IP of Knowledge platform

[dp-redis]
18.3.1.5

[lp-redis-ps:children]
lp-redis

[redis-ps:children]
lp-redis-ps

[redis-exporter-targets:children]
lp-redis

[learning-neo4j-node1]
18.3.0.4            # Neo4j ip of Knowledge platform

[lp-cassandra]
18.3.0.4             # cassandra ip of Knowledge platform

[dp-cassandra]
18.3.0.4             # cassandra ip of Datapipeline

[local]
localhost ansible_connection=local

[raw-broker]        #Druid Broker IP
localhost

[kong-api]
localhost

[composite-search-cluster]
18.3.0.4

[yarn-master]
18.3.1.8

[yarn-slave]
18.3.1.8     #yarn master
18.3.1.9

[yarn:children]
yarn-master
yarn-slave

[core:children]
es
log-es
cassandra
postgresql-master
postgresql-slave
kafka
keycloak
composite-search-cluster
processing-cluster-kafka
yarn

[env:children]
core
local

[dp-druid-broker]
0.0.0.0                # Druid broker IP for druid proxy api

[raw-coordinator]
0.0.0.0

[all:vars]
# If you want to tag your prometheus data with unique cluster ids
# useful in case of prometheus federation
#
# cluster_name=DC1
#
ansible_ssh_user=deployer
ansible_ssh_private_key_file=/var/lib/jenkins/secrets/deployer_ssh_key
logger_es6_host="{{ groups['log-es-2'][0] }}"
